{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485aadc-b06b-48a8-a508-1730d923a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    Helper functions for the pretrained model to be used within our API.\n",
    "\n",
    "    Author: Explore Data Science Academy.\n",
    "\n",
    "    Note:  \n",
    "    ---------------------------------------------------------------------\n",
    "    Please follow the instructions provided within the README.md file\n",
    "    located within this directory for guidance on how to use this script\n",
    "    correctly.\n",
    "\n",
    "    Importantly, you will need to modify this file by adding\n",
    "    your own data preprocessing steps within the `_preprocess_data()`\n",
    "    function.\n",
    "    ----------------------------------------------------------------------\n",
    "\n",
    "    Description: This file contains several functions used to abstract aspects\n",
    "    of model interaction within the API. This includes loading a model from\n",
    "    file, data preprocessing, and model prediction.  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Helper Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def _preprocess_data(data):\n",
    "    \"\"\"Private helper function to preprocess data for model prediction.\n",
    "    \n",
    "    df_train = pd.read_csv('df_train.csv') # load the train data\n",
    "    df_test = pd.read_csv('df_test.csv')  # load the test data\n",
    "\n",
    "    NB: If you have utilised feature engineering/selection in order to create\n",
    "    your final model you will need to define the code here.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        The data payload received within POST requests sent to our API.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame : <class 'pandas.core.frame.DataFrame'>\n",
    "        The preprocessed data, ready to be used our model for prediction.\n",
    "    \"\"\"\n",
    "    # Convert the json string to a python dictionary object\n",
    "    feature_vector_dict = json.loads(data)\n",
    "    # Load the dictionary as a Pandas DataFrame.\n",
    "    feature_vector_df = pd.DataFrame.from_dict([feature_vector_dict])\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # NOTE: You will need to swap the lines below for your own data\n",
    "    # preprocessing methods.\n",
    "    #\n",
    "    # The code below is for demonstration purposes only. You will not\n",
    "    # receive marks for submitting this code in an unchanged state.\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # ----------- Replace this code with your own preprocessing steps --------\n",
    "        #imputing missing values\n",
    "    df_test['Valencia_pressure'] = df_test['Valencia_pressure'].fillna(df_test['Valencia_pressure'].mode()[0])\n",
    "    # impute the mode\n",
    "    df_train['Valencia_pressure'] = df_train['Valencia_pressure'].fillna(df_train['Valencia_pressure'].mode()[0])\n",
    "\n",
    "    # extracting the number from the string \n",
    "    df_test['Valencia_wind_deg'] = df_test['Valencia_wind_deg'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "# extracting the number from the string \n",
    "    df_train['Valencia_wind_deg'] = df_train['Valencia_wind_deg'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "# change the train data type to integer\n",
    "    df_test['Valencia_wind_deg'] = pd.to_numeric(df_test['Valencia_wind_deg'])\n",
    " \n",
    "\n",
    "    # change the test data type to integer\n",
    "    df_train['Valencia_wind_deg'] = pd.to_numeric(df_train['Valencia_wind_deg'])\n",
    " \n",
    "\n",
    "    # extracting the number from the string \n",
    "    df_train['Seville_pressure'] = df_train['Seville_pressure'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "# extracting the number from the string \n",
    "    df_test['Seville_pressure'] = df_test['Seville_pressure'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "# change the data type to integer\n",
    "    df_test['Seville_pressure'] = pd.to_numeric(df_test['Seville_pressure'])\n",
    " \n",
    "    # change the data type to integer\n",
    "    df_train['Seville_pressure'] = pd.to_numeric(df_train['Seville_pressure'])\n",
    " \n",
    "    df_train['Year']  = df_train['time'].astype('datetime64').dt.year\n",
    "    df_train['Month_of_year']  = df_train['time'].astype('datetime64').dt.month\n",
    "    df_train['Week_of_year'] = df_train['time'].astype('datetime64').dt.weekofyear\n",
    "    df_train['Day_of_year']  = df_train['time'].astype('datetime64').dt.dayofyear\n",
    "    df_train['Day_of_month']  = df_train['time'].astype('datetime64').dt.day\n",
    "    df_train['Day_of_week'] = df_train['time'].astype('datetime64').dt.dayofweek\n",
    "    df_train['Hour_of_week'] = ((df_train['time'].astype('datetime64').dt.dayofweek) * 24 + 24) - (24 - df_train['time'].astype('datetime64').dt.hour)\n",
    "    df_train['Hour_of_day']  = df_train['time'].astype('datetime64').dt.hour\n",
    "\n",
    "    df_train = df_train.drop(columns=['Week_of_year','Day_of_year','Hour_of_week', 'Unnamed: 0','time'])\n",
    "    df_test = df_test.drop(columns=['Week_of_year','Day_of_year','Hour_of_week', 'Unnamed: 0','time'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_train)\n",
    "    X_scaled = pd.DataFrame(X_scaled,columns=X.columns)\n",
    "    \n",
    "    predict_vector = feature_vector_df[['Madrid_wind_speed', 'Valencia_wind_deg', 'Bilbao_rain_1h',\n",
    "       'Valencia_wind_speed', 'Seville_humidity', 'Madrid_humidity',\n",
    "       'Bilbao_clouds_all', 'Bilbao_wind_speed', 'Seville_clouds_all',\n",
    "       'Bilbao_wind_deg', 'Barcelona_wind_speed', 'Barcelona_wind_deg',\n",
    "       'Madrid_clouds_all', 'Seville_wind_speed', 'Barcelona_rain_1h',\n",
    "       'Seville_pressure', 'Seville_rain_1h', 'Bilbao_snow_3h',\n",
    "       'Barcelona_pressure', 'Seville_rain_3h', 'Madrid_rain_1h',\n",
    "       'Barcelona_rain_3h', 'Valencia_snow_3h', 'Madrid_weather_id',\n",
    "       'Barcelona_weather_id', 'Bilbao_pressure', 'Seville_weather_id',\n",
    "       'Valencia_pressure', 'Seville_temp_max', 'Bilbao_weather_id', \n",
    "        'Valencia_humidity', 'Year', 'Month_of_year', 'Day_of_month', 'Day_of_week', 'Hour_of_day']]\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    return predict_vector\n",
    "\n",
    "def load_model(path_to_model:str):\n",
    "    \"\"\"Adapter function to load our pretrained model into memory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_model : str\n",
    "        The relative path to the model weights/schema to load.\n",
    "        Note that unless another file format is used, this needs to be a\n",
    "        .pkl file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    <class: sklearn.estimator>\n",
    "        The pretrained model loaded into memory.\n",
    "\n",
    "    \"\"\"\n",
    "    return pickle.load(open(path_to_model, 'rb'))\n",
    "\n",
    "\n",
    "\"\"\" You may use this section (above the make_prediction function) of the python script to implement \n",
    "    any auxiliary functions required to process your model's artifacts.\n",
    "\"\"\"\n",
    "\n",
    "def make_prediction(data, model):\n",
    "    \"\"\"Prepare request data for model prediction.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        The data payload received within POST requests sent to our API.\n",
    "    model : <class: sklearn.estimator>\n",
    "        An sklearn model object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A 1-D python list containing the model prediction.\n",
    "\n",
    "    \"\"\"\n",
    "    # Data preprocessing.\n",
    "    prep_data = _preprocess_data(data)\n",
    "    # Perform prediction with model and preprocessed data.\n",
    "    prediction = model.predict(prep_data)\n",
    "    # Format as list for output standardisation.\n",
    "    return prediction[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3856b9cb-429a-472c-a6ba-68fa8da534a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def _preprocess_data(data):\n",
    "    \"\"\"Private helper function to preprocess data for model prediction.\n",
    "    \n",
    "    df_train = pd.read_csv('df_train.csv') # load the train data\n",
    "    df_test = pd.read_csv('df_test.csv')  # load the test data\n",
    "\n",
    "    NB: If you have utilised feature engineering/selection in order to create\n",
    "    your final model you will need to define the code here.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        The data payload received within POST requests sent to our API.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame : <class 'pandas.core.frame.DataFrame'>\n",
    "        The preprocessed data, ready to be used our model for prediction.\n",
    "    \"\"\"\n",
    "    # Convert the json string to a python dictionary object\n",
    "    feature_vector_dict = json.loads(data)\n",
    "    # Load the dictionary as a Pandas DataFrame.\n",
    "    feature_vector_df = pd.DataFrame.from_dict([feature_vector_dict])\n",
    "\n",
    "    # ---------------------------------------------------------------\n",
    "    # NOTE: You will need to swap the lines below for your own data\n",
    "    # preprocessing methods.\n",
    "    #\n",
    "    # The code below is for demonstration purposes only. You will not\n",
    "    # receive marks for submitting this code in an unchanged state.\n",
    "    # ---------------------------------------------------------------\n",
    "\n",
    "    # ----------- Replace this code with your own preprocessing steps --------\n",
    "        #imputing missing values\n",
    "    # impute the mode\n",
    "    df_train['Valencia_pressure'] = df_train['Valencia_pressure'].fillna(df_train['Valencia_pressure'].mode()[0])\n",
    "\n",
    "\n",
    "# extracting the number from the string \n",
    "    df_train['Valencia_wind_deg'] = df_train['Valencia_wind_deg'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "\n",
    "    # change the test data type to integer\n",
    "    df_train['Valencia_wind_deg'] = pd.to_numeric(df_train['Valencia_wind_deg'])\n",
    " \n",
    "\n",
    "    # extracting the number from the string \n",
    "    df_train['Seville_pressure'] = df_train['Seville_pressure'].str.extract('(\\d+)').astype('int64')\n",
    "\n",
    "\n",
    " \n",
    "    # change the data type to integer\n",
    "    df_train['Seville_pressure'] = pd.to_numeric(df_train['Seville_pressure'])\n",
    " \n",
    "    df_train['Year']  = df_train['time'].astype('datetime64').dt.year\n",
    "    df_train['Month_of_year']  = df_train['time'].astype('datetime64').dt.month\n",
    "    df_train['Week_of_year'] = df_train['time'].astype('datetime64').dt.weekofyear\n",
    "    df_train['Day_of_year']  = df_train['time'].astype('datetime64').dt.dayofyear\n",
    "    df_train['Day_of_month']  = df_train['time'].astype('datetime64').dt.day\n",
    "    df_train['Day_of_week'] = df_train['time'].astype('datetime64').dt.dayofweek\n",
    "    df_train['Hour_of_week'] = ((df_train['time'].astype('datetime64').dt.dayofweek) * 24 + 24) - (24 - df_train['time'].astype('datetime64').dt.hour)\n",
    "    df_train['Hour_of_day']  = df_train['time'].astype('datetime64').dt.hour\n",
    "\n",
    "    df_train = df_train.drop(columns=['Week_of_year','Day_of_year','Hour_of_week', 'Unnamed: 0','time'])\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_train)\n",
    "    X_scaled = pd.DataFrame(X_scaled,columns=df_train.columns)\n",
    "    \n",
    "    predict_vector = X_scaled[['Madrid_wind_speed', 'Valencia_wind_deg', 'Bilbao_rain_1h',\n",
    "       'Valencia_wind_speed', 'Seville_humidity', 'Madrid_humidity',\n",
    "       'Bilbao_clouds_all', 'Bilbao_wind_speed', 'Seville_clouds_all',\n",
    "       'Bilbao_wind_deg', 'Barcelona_wind_speed', 'Barcelona_wind_deg',\n",
    "       'Madrid_clouds_all', 'Seville_wind_speed', 'Barcelona_rain_1h',\n",
    "       'Seville_pressure', 'Seville_rain_1h', 'Bilbao_snow_3h',\n",
    "       'Barcelona_pressure', 'Seville_rain_3h', 'Madrid_rain_1h',\n",
    "       'Barcelona_rain_3h', 'Valencia_snow_3h', 'Madrid_weather_id',\n",
    "       'Barcelona_weather_id', 'Bilbao_pressure', 'Seville_weather_id',\n",
    "       'Valencia_pressure', 'Seville_temp_max', 'Madrid_pressure',\n",
    "       'Valencia_temp_max', 'Valencia_temp', 'Bilbao_weather_id',\n",
    "       'Seville_temp', 'Valencia_humidity', 'Valencia_temp_min',\n",
    "       'Barcelona_temp_max', 'Madrid_temp_max', 'Barcelona_temp',\n",
    "       'Bilbao_temp_min', 'Bilbao_temp', 'Barcelona_temp_min',\n",
    "       'Bilbao_temp_max', 'Seville_temp_min', 'Madrid_temp', 'Madrid_temp_min',\n",
    "       'Year', 'Month_of_year', 'Day_of_month', 'Day_of_week', 'Hour_of_day']]\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    return predict_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccfc047-7aca-446a-affc-e4d5928ee56f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NESSA~1.DES\\AppData\\Local\\Temp/ipykernel_9052/2865260765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_scaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d5964-995e-41e5-952d-62bf56e1681d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
